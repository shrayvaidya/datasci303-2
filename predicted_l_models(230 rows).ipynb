{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0dc07fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "964f0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('predicted_l_230rows_newdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc2766b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 21, 30, 32, 34, 37, 40, 42, 42, 46, 46, 46, 52, 52, 54, 54, 56, 56, 61, 61, 61, 61, 61, 67, 68, 69, 69, 69, 69, 69, 69, 75, 75, 75, 78, 78, 78, 81, 81, 81, 81, 87, 87, 90, 90, 90, 90, 94, 94, 97, 97, 97, 97, 97, 103, 103, 103, 103, 103, 103, 110, 110, 110, 110, 115, 115, 115, 115, 115, 120, 120, 120, 120, 124, 124, 124, 124, 124, 124, 124, 132, 133, 133, 133, 133, 133, 133, 133, 140, 140, 140, 140, 145, 145, 145, 145, 145, 151, 151, 151, 151, 151, 156, 156, 156, 159, 159, 159, 159, 159, 165, 165, 165, 165, 165, 171, 171, 171, 171, 171, 176, 176, 176, 176, 176, 181, 181, 181, 181, 181, 181, 187, 187, 187, 187, 187, 192, 192, 192, 192, 192, 192, 198, 198, 198, 198, 202, 202, 202, 202, 202, 207, 207, 207, 207, 207, 207, 207, 207, 207, 216, 216, 216, 216, 216, 216, 216, 223, 223, 223, 223, 223, 223, 223, 223, 14, 21, 30, 32, 34, 37, 40, 42, 42, 46, 46, 46, 52, 52, 54, 54, 56, 56, 61, 61, 61, 61, 61, 67, 68, 69, 69, 69, 69, 69, 69, 75, 75, 75, 78, 78, 78, 81, 81, 81, 81, 87, 87, 90, 90, 90, 90, 94, 94, 97, 97, 97, 97, 97, 103, 103, 103, 103, 103, 103, 110, 110, 110, 110, 115, 115, 115, 115, 115, 120, 120, 120, 120, 124, 124, 124, 124, 124, 124, 124, 132, 133, 133, 133, 133, 133, 133, 133, 140, 140, 140, 140, 145, 145, 145, 145, 145, 151, 151, 151, 151, 151, 156, 156, 156, 159, 159, 159, 159, 159, 165, 165, 165, 165, 165, 171, 171, 171, 171, 171, 176, 176, 176, 176, 176, 181, 181, 181, 181, 181, 181, 187, 187, 187, 187, 187, 192, 192, 192, 192, 192, 192, 198, 198, 198, 198, 202, 202, 202, 202, 202, 207, 207, 207, 207, 207, 207, 207, 207, 207, 216, 216, 216, 216, 216, 216, 216, 223, 223, 223, 223, 223, 223, 223, 223, 14, 21, 30, 32, 34, 37, 40, 42, 42, 46, 46, 46, 52, 52, 54, 54, 56, 56, 61, 61, 61, 61, 61, 67, 68, 69, 69, 69, 69, 69, 69, 75, 75, 75, 78, 78, 78, 81, 81, 81, 81, 87, 87, 90, 90, 90, 90, 94, 94, 97, 97, 97, 97, 97, 103, 103, 103, 103, 103, 103, 110, 110, 110, 110, 115, 115, 115, 115, 115, 120, 120, 120, 120, 124, 124, 124, 124, 124, 124, 124, 132, 133, 133, 133, 133, 133, 133, 133, 140, 140, 140, 140, 145, 145, 145, 145, 145, 151, 151, 151, 151, 151, 156, 156, 156, 159, 159, 159, 159, 159, 165, 165, 165, 165, 165, 171, 171, 171, 171, 171, 176, 176, 176, 176, 176, 181, 181, 181, 181, 181, 181, 187, 187, 187, 187, 187, 192, 192, 192, 192, 192, 192, 198, 198, 198, 198, 202, 202, 202, 202, 202, 207, 207, 207, 207, 207, 207, 207, 207, 207, 216, 216, 216, 216, 216, 216, 216, 223, 223, 223, 223, 223, 223, 223, 223, 14, 21, 30, 32, 34, 37, 40, 42, 42, 46, 46, 46, 52, 52, 54, 54, 56, 56, 61, 61, 61, 61, 61, 67, 68, 69, 69, 69, 69, 69, 69, 75, 75, 75, 78, 78, 78, 81, 81, 81, 81, 87, 87, 90, 90, 90, 90, 94, 94, 97, 97, 97, 97, 97, 103, 103, 103, 103, 103, 103, 110, 110, 110, 110, 115, 115, 115, 115, 115, 120, 120, 120, 120, 124, 124, 124, 124, 124, 124, 124, 132, 133, 133, 133, 133, 133, 133, 133, 140, 140, 140, 140, 145, 145, 145, 145, 145, 151, 151, 151, 151, 151, 156, 156, 156, 159, 159, 159, 159, 159, 165, 165, 165, 165, 165, 171, 171, 171, 171, 171, 176, 176, 176, 176, 176, 181, 181, 181, 181, 181, 181, 187, 187, 187, 187, 187, 192, 192, 192, 192, 192, 192, 198, 198, 198, 198, 202, 202, 202, 202, 202, 207, 207, 207, 207, 207, 207, 207, 207, 207, 216, 216, 216, 216, 216, 216, 216, 223, 223, 223, 223, 223, 223, 223, 223]\n",
      "-----\n",
      "[30, 81, 52, 46, 133, 81, 90, 56, 81, 90, 81, 61, 115, 115, 115, 81, 61, 42, 46, 187, 94, 81, 75, 90, 75, 90, 115, 223, 54, 115, 69, 94, 181, 140, 103, 61, 81, 176, 90, 56, 37, 171, 223, 54, 124, 78, 61, 124, 151, 61, 97, 181, 207, 133, 133, 69, 145, 67, 103, 133, 97, 69, 133, 202, 54, 69, 52, 97, 61, 61, 176, 78, 145, 94, 103, 34, 133, 90, 94, 140, 115, 187, 61, 181, 198, 171, 171, 145, 103, 187, 110, 97, 207, 103, 151, 110, 81, 132, 120, 171, 124, 171, 133, 145, 103, 151, 97, 207, 124, 207, 176, 223, 207, 61, 207, 187, 151, 69, 207, 124, 216, 181, 223, 165, 192, 181, 151, 181, 133, 156, 207, 176, 171, 223, 124, 198, 223, 56, 81, 207, 207, 124, 223, 207, 110, 216, 216, 216, 181, 67, 207, 202, 171, 223, 216, 198, 42, 181, 216, 198, 192, 223, 216, 97, 207, 207, 202, 181, 223, 202, 223, 81, 181, 216, 202, 30, 81, 52, 46, 133, 81, 90, 56, 81, 90, 81, 61, 115, 115, 115, 81, 61, 42, 46, 187, 94, 81, 75, 90, 75, 90, 115, 223, 54, 115, 69, 94, 181, 140, 103, 61, 81, 176, 90, 56, 37, 171, 223, 54, 124, 78, 61, 124, 151, 61, 97, 181, 207, 133, 133, 69, 145, 67, 103, 133, 97, 69, 133, 202, 54, 69, 52, 97, 61, 61, 176, 78, 145, 94, 103, 34, 133, 90, 94, 140, 115, 187, 61, 181, 198, 171, 171, 145, 103, 187, 110, 97, 207, 103, 151, 110, 81, 132, 120, 171, 124, 171, 133, 145, 103, 151, 97, 207, 124, 207, 176, 223, 207, 61, 207, 187, 151, 69, 207, 124, 216, 181, 223, 165, 192, 181, 151, 181, 133, 156, 207, 176, 171, 223, 124, 198, 223, 56, 81, 207, 207, 124, 223, 207, 110, 216, 216, 216, 181, 67, 207, 202, 171, 223, 216, 198, 42, 181, 216, 198, 192, 223, 216, 97, 207, 207, 202, 181, 223, 202, 223, 81, 181, 216, 202, 30, 81, 52, 46, 133, 81, 90, 56, 81, 90, 81, 61, 115, 115, 115, 81, 61, 42, 46, 187, 94, 81, 75, 90, 75, 90, 115, 223, 54, 115, 69, 94, 181, 140, 103, 61, 81, 176, 90, 56, 37, 171, 223, 54, 124, 78, 61, 124, 151, 61, 97, 181, 207, 133, 133, 69, 145, 67, 103, 133, 97, 69, 133, 202, 54, 69, 52, 97, 61, 61, 176, 78, 145, 94, 103, 34, 133, 90, 94, 140, 115, 187, 61, 181, 198, 171, 171, 145, 103, 187, 110, 97, 207, 103, 151, 110, 81, 132, 120, 171, 124, 171, 133, 145, 103, 151, 97, 207, 124, 207, 176, 223, 207, 61, 207, 187, 151, 69, 207, 124, 216, 181, 223, 165, 192, 181, 151, 181, 133, 156, 207, 176, 171, 223, 124, 198, 223, 56, 81, 207, 207, 124, 223, 207, 110, 216, 216, 216, 181, 67, 207, 202, 171, 223, 216, 198, 42, 181, 216, 198, 192, 223, 216, 97, 207, 207, 202, 181, 223, 202, 223, 81, 181, 216, 202, 30, 81, 52, 46, 133, 81, 90, 56, 81, 90, 81, 61, 115, 115, 115, 81, 61, 42, 46, 187, 94, 81, 75, 90, 75, 90, 115, 223, 54, 115, 69, 94, 181, 140, 103, 61, 81, 176, 90, 56, 37, 171, 223, 54, 124, 78, 61, 124, 151, 61, 97, 181, 207, 133, 133, 69, 145, 67, 103, 133, 97, 69, 133, 202, 54, 69, 52, 97, 61, 61, 176, 78, 145, 94, 103, 34, 133, 90, 94, 140, 115, 187, 61, 181, 198, 171, 171, 145, 103, 187, 110, 97, 207, 103, 151, 110, 81, 132, 120, 171, 124, 171, 133, 145, 103, 151, 97, 207, 124, 207, 176, 223, 207, 61, 207, 187, 151, 69, 207, 124, 216, 181, 223, 165, 192, 181, 151, 181, 133, 156, 207, 176, 171, 223, 124, 198, 223, 56, 81, 207, 207, 124, 223, 207, 110, 216, 216, 216, 181, 67, 207, 202, 171, 223, 216, 198, 42, 181, 216, 198, 192, 223, 216, 97, 207, 207, 202, 181, 223, 202, 223, 81, 181, 216, 202]\n",
      "Accuracy: 0.045714285714285714\n"
     ]
    }
   ],
   "source": [
    "X = df[['act_avg', 'sat_avg','percent_receiving_aid',\n",
    "       'cost_after_aid', 'hs_gpa_avg','businessRepScore', 'tuition',\n",
    "       'engineeringRepScore','branches', 'admission_rate', \n",
    "       'ug_enrollment', 'percent_white', 'percent_black', 'percent_hispanic',\n",
    "       'percent_asian', 'percent_aian', 'percent_nhpi', 'percent_twoormore',\n",
    "       'percent_nra', 'percent_unknown', 'percent_parttime', 'avg_cost',\n",
    "       'instante_tuition', 'outstate_tuition', 'tuition_revenue_per',\n",
    "       'instructional_expenditure_per', 'avg_faculty_salary',\n",
    "       'ft_faculty_rate', 'avg_net_price', 'number_titleIV', 'sat_avg']]\n",
    "y = df[['rankingSortRank']]\n",
    "loocv = LeaveOneOut()\n",
    "loocv.get_n_splits(X)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "high_df = []\n",
    "low_df = []\n",
    "high_predicted = []\n",
    "low_predicted = []\n",
    "\n",
    "for train_index, test_index in loocv.split(X):\n",
    "\n",
    "    X_train=X.loc[train_index]\n",
    "    X_test=X.loc[test_index]\n",
    "    y_train=y.loc[train_index]\n",
    "    y_test=y.loc[test_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    true.append(y_test['rankingSortRank'].values[0])\n",
    "    predicted.append(y_pred[0])\n",
    "    \n",
    "    #classifying into high and low\n",
    "    \n",
    "    if y_test['rankingSortRank'].values[0] < 100:\n",
    "        high_df.append(test_index[0])\n",
    "    else:\n",
    "        low_df.append(test_index[0])\n",
    "    if y_pred[0] < 100:\n",
    "        high_predicted.append(test_index[0])\n",
    "    else:\n",
    "        low_predicted.append(test_index[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "print(true)\n",
    "print(\"-----\")\n",
    "print(predicted)\n",
    "accuracy = accuracy_score(true, predicted)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a19526a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
      "-----\n",
      "[54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174]\n",
      "prediction below-----------------\n",
      "[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 28, 30, 31, 35, 36, 38, 39, 40, 43, 45, 46, 49, 50, 55, 57, 60, 61, 64, 65, 66, 67, 68, 69, 71, 73, 75, 77, 78, 82, 91, 96, 106, 113, 117, 137, 138, 149, 156, 163, 171]\n",
      "-----\n",
      "[4, 12, 13, 14, 19, 26, 27, 29, 32, 33, 34, 37, 41, 42, 44, 47, 48, 51, 52, 53, 54, 56, 58, 59, 62, 63, 70, 72, 74, 76, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174]\n"
     ]
    }
   ],
   "source": [
    "print(high_df)\n",
    "print(\"-----\")\n",
    "print(low_df)\n",
    "print(\"prediction below-----------------\")\n",
    "print(high_predicted)\n",
    "print(\"-----\")\n",
    "print(low_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c40770a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ml = df.iloc[high_predicted,:]\n",
    "predicted_ml.to_csv('predicted_ml_230rows.csv')\n",
    "predicted_lf = df.iloc[low_predicted,:]\n",
    "predicted_lf.to_csv('predicted_lf_230rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be62fc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_ml = 0\n",
    "for i in high_df:\n",
    "    for j in high_predicted:\n",
    "        if i ==j:\n",
    "            correct_ml += 1 \n",
    "correct_lf = 0\n",
    "for i in low_df:\n",
    "    for j in low_predicted:\n",
    "        if i ==j:\n",
    "            correct_lf += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fe0630f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7314285714285714"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(correct_ml + correct_lf)/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5945affa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>rankingSortRank</td> <th>  R-squared:         </th> <td>   0.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   37.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 05 Mar 2023</td> <th>  Prob (F-statistic):</th> <td>3.45e-54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:07:55</td>     <th>  Log-Likelihood:    </th> <td> -762.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   175</td>      <th>  AIC:               </th> <td>   1586.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   144</td>      <th>  BIC:               </th> <td>   1684.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    30</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                     <td> 3856.4286</td> <td> 2.16e+04</td> <td>    0.179</td> <td> 0.858</td> <td>-3.88e+04</td> <td> 4.65e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>act_avg</th>                       <td>   -6.0918</td> <td>    1.553</td> <td>   -3.923</td> <td> 0.000</td> <td>   -9.161</td> <td>   -3.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sat_avg</th>                       <td>   -0.0127</td> <td>    0.038</td> <td>   -0.336</td> <td> 0.738</td> <td>   -0.088</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percent_receiving_aid</th>         <td>    0.1053</td> <td>    0.184</td> <td>    0.572</td> <td> 0.568</td> <td>   -0.259</td> <td>    0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cost_after_aid</th>                <td>    0.0007</td> <td>    0.000</td> <td>    1.504</td> <td> 0.135</td> <td>   -0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hs_gpa_avg</th>                    <td>  -25.2816</td> <td>   12.069</td> <td>   -2.095</td> <td> 0.038</td> <td>  -49.137</td> <td>   -1.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>businessRepScore</th>              <td>  -23.0837</td> <td>    5.965</td> <td>   -3.870</td> <td> 0.000</td> <td>  -34.875</td> <td>  -11.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tuition</th>                       <td>    0.0010</td> <td>    0.001</td> <td>    1.020</td> <td> 0.309</td> <td>   -0.001</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineeringRepScore</th>           <td>   -3.8212</td> <td>    4.474</td> <td>   -0.854</td> <td> 0.394</td> <td>  -12.664</td> <td>    5.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>branches</th>                      <td>   -0.7918</td> <td>    0.894</td> <td>   -0.886</td> <td> 0.377</td> <td>   -2.559</td> <td>    0.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>admission_rate</th>                <td>   15.6470</td> <td>   14.892</td> <td>    1.051</td> <td> 0.295</td> <td>  -13.787</td> <td>   45.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ug_enrollment</th>                 <td>-7.428e-05</td> <td>    0.000</td> <td>   -0.168</td> <td> 0.867</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percent_white</th>                 <td>-3321.7044</td> <td> 2.16e+04</td> <td>   -0.154</td> <td> 0.878</td> <td> -4.6e+04</td> <td> 3.93e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percent_black</th>                 <td>-3293.8608</td> <td> 2.16e+04</td> <td>   -0.153</td> <td> 0.879</td> <td>-4.59e+04</td> <td> 3.93e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percent_hispanic</th>              <td>-3324.4738</td> <td> 2.16e+04</td> <td>   -0.154</td> <td> 0.878</td> <td> -4.6e+04</td> <td> 3.93e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percent_asian</th>                 <td>-3265.8465</td> <td> 2.16e+04</td> <td>   -0.151</td> <td> 0.880</td> <td>-4.59e+04</td> <td> 3.94e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percent_aian</th>                  <td>-3639.7175</td> <td> 2.16e+04</td> <td>   -0.169</td> <td> 0.866</td> <td>-4.63e+04</td> <td>  3.9e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percent_nhpi</th>                  <td>-4786.0854</td> <td> 2.16e+04</td> <td>   -0.222</td> <td> 0.825</td> <td>-4.74e+04</td> <td> 3.78e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percent_twoormore</th>             <td>-3213.6662</td> <td> 2.16e+04</td> <td>   -0.149</td> <td> 0.882</td> <td>-4.59e+04</td> <td> 3.94e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percent_nra</th>                   <td>-3300.8673</td> <td> 2.16e+04</td> <td>   -0.153</td> <td> 0.879</td> <td>-4.59e+04</td> <td> 3.93e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percent_unknown</th>               <td>-3286.1352</td> <td> 2.16e+04</td> <td>   -0.152</td> <td> 0.879</td> <td>-4.59e+04</td> <td> 3.94e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>percent_parttime</th>              <td>  154.6312</td> <td>   28.909</td> <td>    5.349</td> <td> 0.000</td> <td>   97.490</td> <td>  211.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_cost</th>                      <td>   -0.0034</td> <td>    0.001</td> <td>   -3.847</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>instante_tuition</th>              <td>    0.0041</td> <td>    0.001</td> <td>    4.273</td> <td> 0.000</td> <td>    0.002</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>outstate_tuition</th>              <td>   -0.0025</td> <td>    0.001</td> <td>   -2.448</td> <td> 0.016</td> <td>   -0.005</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tuition_revenue_per</th>           <td>-7.059e-05</td> <td>    0.001</td> <td>   -0.097</td> <td> 0.923</td> <td>   -0.002</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>instructional_expenditure_per</th> <td>   -0.0010</td> <td>    0.000</td> <td>   -2.099</td> <td> 0.038</td> <td>   -0.002</td> <td>-5.97e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_faculty_salary</th>            <td>   -0.0033</td> <td>    0.002</td> <td>   -2.072</td> <td> 0.040</td> <td>   -0.006</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ft_faculty_rate</th>               <td>    0.5843</td> <td>   10.125</td> <td>    0.058</td> <td> 0.954</td> <td>  -19.429</td> <td>   20.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_net_price</th>                 <td>   -0.0003</td> <td>    0.001</td> <td>   -0.477</td> <td> 0.634</td> <td>   -0.002</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_titleIV</th>                <td>   -0.0013</td> <td>    0.004</td> <td>   -0.302</td> <td> 0.763</td> <td>   -0.010</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.094</td> <th>  Durbin-Watson:     </th> <td>   1.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.579</td> <th>  Jarque-Bera (JB):  </th> <td>   0.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.007</td> <th>  Prob(JB):          </th> <td>   0.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.317</td> <th>  Cond. No.          </th> <td>3.51e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.51e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        rankingSortRank   R-squared:                       0.888\n",
       "Model:                            OLS   Adj. R-squared:                  0.864\n",
       "Method:                 Least Squares   F-statistic:                     37.99\n",
       "Date:                Sun, 05 Mar 2023   Prob (F-statistic):           3.45e-54\n",
       "Time:                        16:07:55   Log-Likelihood:                -762.02\n",
       "No. Observations:                 175   AIC:                             1586.\n",
       "Df Residuals:                     144   BIC:                             1684.\n",
       "Df Model:                          30                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "Intercept                      3856.4286   2.16e+04      0.179      0.858   -3.88e+04    4.65e+04\n",
       "act_avg                          -6.0918      1.553     -3.923      0.000      -9.161      -3.022\n",
       "sat_avg                          -0.0127      0.038     -0.336      0.738      -0.088       0.062\n",
       "percent_receiving_aid             0.1053      0.184      0.572      0.568      -0.259       0.469\n",
       "cost_after_aid                    0.0007      0.000      1.504      0.135      -0.000       0.002\n",
       "hs_gpa_avg                      -25.2816     12.069     -2.095      0.038     -49.137      -1.426\n",
       "businessRepScore                -23.0837      5.965     -3.870      0.000     -34.875     -11.293\n",
       "tuition                           0.0010      0.001      1.020      0.309      -0.001       0.003\n",
       "engineeringRepScore              -3.8212      4.474     -0.854      0.394     -12.664       5.021\n",
       "branches                         -0.7918      0.894     -0.886      0.377      -2.559       0.975\n",
       "admission_rate                   15.6470     14.892      1.051      0.295     -13.787      45.081\n",
       "ug_enrollment                 -7.428e-05      0.000     -0.168      0.867      -0.001       0.001\n",
       "percent_white                 -3321.7044   2.16e+04     -0.154      0.878    -4.6e+04    3.93e+04\n",
       "percent_black                 -3293.8608   2.16e+04     -0.153      0.879   -4.59e+04    3.93e+04\n",
       "percent_hispanic              -3324.4738   2.16e+04     -0.154      0.878    -4.6e+04    3.93e+04\n",
       "percent_asian                 -3265.8465   2.16e+04     -0.151      0.880   -4.59e+04    3.94e+04\n",
       "percent_aian                  -3639.7175   2.16e+04     -0.169      0.866   -4.63e+04     3.9e+04\n",
       "percent_nhpi                  -4786.0854   2.16e+04     -0.222      0.825   -4.74e+04    3.78e+04\n",
       "percent_twoormore             -3213.6662   2.16e+04     -0.149      0.882   -4.59e+04    3.94e+04\n",
       "percent_nra                   -3300.8673   2.16e+04     -0.153      0.879   -4.59e+04    3.93e+04\n",
       "percent_unknown               -3286.1352   2.16e+04     -0.152      0.879   -4.59e+04    3.94e+04\n",
       "percent_parttime                154.6312     28.909      5.349      0.000      97.490     211.772\n",
       "avg_cost                         -0.0034      0.001     -3.847      0.000      -0.005      -0.002\n",
       "instante_tuition                  0.0041      0.001      4.273      0.000       0.002       0.006\n",
       "outstate_tuition                 -0.0025      0.001     -2.448      0.016      -0.005      -0.000\n",
       "tuition_revenue_per           -7.059e-05      0.001     -0.097      0.923      -0.002       0.001\n",
       "instructional_expenditure_per    -0.0010      0.000     -2.099      0.038      -0.002   -5.97e-05\n",
       "avg_faculty_salary               -0.0033      0.002     -2.072      0.040      -0.006      -0.000\n",
       "ft_faculty_rate                   0.5843     10.125      0.058      0.954     -19.429      20.597\n",
       "avg_net_price                    -0.0003      0.001     -0.477      0.634      -0.002       0.001\n",
       "number_titleIV                   -0.0013      0.004     -0.302      0.763      -0.010       0.007\n",
       "==============================================================================\n",
       "Omnibus:                        1.094   Durbin-Watson:                   1.562\n",
       "Prob(Omnibus):                  0.579   Jarque-Bera (JB):                0.734\n",
       "Skew:                           0.007   Prob(JB):                        0.693\n",
       "Kurtosis:                       3.317   Cond. No.                     3.51e+09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.51e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = ['act_avg', 'sat_avg','percent_receiving_aid',\n",
    "       'cost_after_aid', 'hs_gpa_avg','businessRepScore', 'tuition',\n",
    "       'engineeringRepScore','branches', 'admission_rate', \n",
    "       'ug_enrollment', 'percent_white', 'percent_black', 'percent_hispanic',\n",
    "       'percent_asian', 'percent_aian', 'percent_nhpi', 'percent_twoormore',\n",
    "       'percent_nra', 'percent_unknown', 'percent_parttime', 'avg_cost',\n",
    "       'instante_tuition', 'outstate_tuition', 'tuition_revenue_per',\n",
    "       'instructional_expenditure_per', 'avg_faculty_salary',\n",
    "       'ft_faculty_rate', 'avg_net_price', 'number_titleIV', 'sat_avg']\n",
    "model = sm.ols('rankingSortRank~' + '+'.join(predictors),data = df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24e9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
